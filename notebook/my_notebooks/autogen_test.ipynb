{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f134feab-e8b6-4c27-8d3c-0740c037ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42e27891-fbb7-481f-a4b9-c76306a4767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi3 = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"microsoft/Phi-3-mini-4k-instruct-gguf\",\n",
    "            \"base_url\": \"http://172.31.80.1:5506/v1\",\n",
    "            \"api_key\": \"lm-studio\",\n",
    "        },\n",
    "    ],\n",
    "    \"cache_seed\": None,  # Disable caching.\n",
    "}\n",
    "\n",
    "llama3_8b = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "            \"base_url\": \"http://172.31.80.1:5506/v1\",\n",
    "            \"api_key\": \"lm-studio\",\n",
    "        },\n",
    "    ],\n",
    "    \"cache_seed\": None,  # Disable caching.\n",
    "}\n",
    "\n",
    "llama3_42b = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"InferenceIllusionist/llama3-42b-v0-iMat-GGUF\",\n",
    "            \"base_url\": \"http://172.31.80.1:5506/v1\",\n",
    "            \"api_key\": \"lm-studio\",\n",
    "        },\n",
    "    ],\n",
    "    \"cache_seed\": None,  # Disable caching.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff3ce2c-547c-40d6-bae7-c3b604aa0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=llama3_8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb6345db-3309-4c8e-9c0e-bdec5ba77b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jack = ConversableAgent(\n",
    "    \"Jack\",\n",
    "    llm_config=llm,\n",
    "    system_message=\"Your name is Jack and you are a comedian in a two-person comedy show.\",\n",
    "    human_input_mode='NEVER',\n",
    "    max_consecutive_auto_reply=1\n",
    "    #is_termination_msg=lambda msg: \"good bye\" or \"goodbye\" in msg[\"content\"].lower(),\n",
    ")\n",
    "adriana = ConversableAgent(\n",
    "    \"Adriana\",\n",
    "    llm_config=llm,\n",
    "    system_message=\"Your name is Adriana and you are a comedian in two-person comedy show.\",\n",
    "    human_input_mode='NEVER',\n",
    "    max_consecutive_auto_reply=3\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b3a50bf-fb68-470b-8234-f55a2d017c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJack\u001b[0m (to Adriana):\n",
      "\n",
      "Adriana, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdriana\u001b[0m (to Jack):\n",
      "\n",
      "Here's one: Why don't scientists trust atoms? Because they make up everything! (get it?) *wink* My partner in crime, Alex, is probably rolling his eyes at my terrible puns right now... but hey, someone's gotta keep the laughter alive! What do you think?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJack\u001b[0m (to Adriana):\n",
      "\n",
      "*laughs* Ahah, that's a great one, Adriana! I love it! *plays along* Yeah, Alex might be groaning in the background, but we know our audience is loving it! You're killing it out there!\n",
      "\n",
      "Now, my turn! Why did the scarecrow win an award? Because he was outstanding in his field! *wink*\n",
      "\n",
      "What do you think, folks? Do we have a pun-filled duo on our hands?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdriana\u001b[0m (to Jack):\n",
      "\n",
      "*laughs* Oh, burn! I mean, nice one! *applauds* You're absolutely right, Alex is probably face-palming as we speak!\n",
      "\n",
      "And OOOOH, your joke is OUTSTANDING in its field (sorry, had to!)! That's a classic, and it never gets old! *high-fives*\n",
      "\n",
      "You know what they say: \"Puns are the highest form of comedy\"... or was that just Alex trying to convince us?\n",
      "\n",
      "Alright, alright, let's get this pun-filled party started! Who's ready for another round?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = jack.initiate_chat(adriana, message=\"Adriana, tell me a joke.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99c6df9a-4122-4213-8f72-744d88a4203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "I have a number between 1 and 50. Guess it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Sounds like fun!\n",
      "\n",
      "My first guess is... 25!\n",
      "\n",
      "Is my guess too high or too low?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please give feedback to agent_guess_number. Press enter or type 'exit' to stop the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent_with_number = ConversableAgent(\n",
    "    \"agent_with_number\",\n",
    "    system_message=\"You are playing a game of guess-my-number. You have the number 25 in your mind, and I will try to guess it. If I guess too high, say 'too high', if I guess too low, say 'too low'.\",\n",
    "    llm_config=llm,\n",
    "    is_termination_msg=lambda msg: \"25\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
    "    human_input_mode=\"TERMINATE\", \n",
    "    max_consecutive_auto_reply=1\n",
    ")\n",
    "\n",
    "agent_guess_number = ConversableAgent(\n",
    "    \"agent_guess_number\",\n",
    "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n",
    "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n",
    "    \"you should guess a higher number. \",\n",
    "    llm_config=llm,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "result = agent_with_number.initiate_chat(\n",
    "    agent_guess_number,\n",
    "    message=\"I have a number between 1 and 50. Guess it!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca4d688-93ca-4dbb-8596-1b3f8a392278",
   "metadata": {},
   "source": [
    "Code Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1aeb487-0b64-4ca4-9c9b-0f553cb38150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "\n",
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a local command line code executor.\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration.\n",
    "code_executor_agent = ConversableAgent(\n",
    "    \"code_executor_agent\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the local command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ee6dadf-54dc-4d80-b712-ab666f3cea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to the sender. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\u001b[0m\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: Scatter plot saved to scatter.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_with_code_block = \"\"\"This is a message with code block.\n",
    "The code block is below:\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.random.randint(0, 100, 100)\n",
    "y = np.random.randint(0, 100, 100)\n",
    "plt.scatter(x, y)\n",
    "plt.savefig('scatter.png')\n",
    "print('Scatter plot saved to scatter.png')\n",
    "```\n",
    "This is the end of the message.\n",
    "\"\"\"\n",
    "\n",
    "# Generate a reply for the given code.\n",
    "reply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": message_with_code_block}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b7229bd6-d149-4759-b972-fbf6b505de82",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/tmppq2segkt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(temp_dir\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/tmppq2segkt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(temp_dir.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ccab5da4-17b2-483a-b8a7-aed4d40a5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc19629-3c64-4988-b024-1bb07e42540b",
   "metadata": {},
   "source": [
    "Code Executor - Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b742689b-5dcc-47b6-a0f8-e8879507e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.coding import DockerCommandLineCodeExecutor\n",
    "\n",
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a Docker command line code executor.\n",
    "executor = DockerCommandLineCodeExecutor(\n",
    "    image=\"python:3.12-slim\",  # Execute code using the given docker image name.\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration that uses docker.\n",
    "code_executor_agent_using_docker = ConversableAgent(\n",
    "    \"code_executor_agent_docker\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the docker command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")\n",
    "\n",
    "# When the code executor is no longer used, stop it to release the resources.\n",
    "# executor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ceeadc5-2624-4318-aade-7f18cdb85467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to the sender. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\u001b[0m\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: Traceback (most recent call last):\n",
      "  File \"/workspace/tmp_code_e24bf32d4a21990fb9e4b5eb889ebe5a.py\", line 1, in <module>\n",
      "    import numpy as np\n",
      "ModuleNotFoundError: No module named 'numpy'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_with_code_block = \"\"\"This is a message with code block.\n",
    "The code block is below:\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.random.randint(0, 100, 100)\n",
    "y = np.random.randint(0, 100, 100)\n",
    "plt.scatter(x, y)\n",
    "plt.savefig('scatter.png')\n",
    "print('Scatter plot saved to scatter.png')\n",
    "```\n",
    "This is the end of the message.\n",
    "\"\"\"\n",
    "\n",
    "# Generate a reply for the given code.\n",
    "reply = code_executor_agent_using_docker.generate_reply(messages=[{\"role\": \"user\", \"content\": message_with_code_block}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda32b5-05a1-4615-b31d-74a323696b8b",
   "metadata": {},
   "source": [
    "Code Writer and Executor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c4ea7ca-8b01-4b78-badf-6772488bf877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code writer agent's system message is to instruct the LLM on how to use\n",
    "# the code executor in the code executor agent.\n",
    "code_writer_system_message = \"\"\"You are a helpful AI assistant.\n",
    "Solve tasks using your coding and language skills.\n",
    "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
    "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. \n",
    "After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
    "2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
    "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
    "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
    "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
    "Reply 'TERMINATE' in the end when everything is done.\n",
    "\"\"\"\n",
    "\n",
    "code_writer_agent = ConversableAgent(\n",
    "    \"code_writer_agent\",\n",
    "    system_message=code_writer_system_message,\n",
    "    llm_config=llm,\n",
    "    code_execution_config=False,  # Turn off code execution for this agent.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6de86feb-d940-4d58-99a5-546b84fc8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a Docker command line code executor.\n",
    "executor = DockerCommandLineCodeExecutor(\n",
    "    image=\"python:3.12-slim\",  # Execute code using the given docker image name.\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration that uses docker.\n",
    "code_executor_agent_using_docker = ConversableAgent(\n",
    "    \"code_executor_agent_docker\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the docker command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7cee9163-95cb-41d3-9f19-697d5717a2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcode_executor_agent_docker\u001b[0m (to code_writer_agent):\n",
      "\n",
      "Write Python code to calculate the 14th Fibonacci number.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mcode_writer_agent\u001b[0m (to code_executor_agent_docker):\n",
      "\n",
      "Here's a simple Python function that calculates the nth Fibonacci number using recursion:\n",
      "\n",
      "```\n",
      "sh\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return \"Input should be positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "```\n",
      "\n",
      "However, this recursive solution is not efficient for large values of `n` because it does a lot of repeated computation. We can use an iterative approach to solve this problem efficiently:\n",
      "\n",
      "```\n",
      "sh\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return \"Input should be positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "```\n",
      "\n",
      "You can call this function with the desired Fibonacci number as an argument:\n",
      "\n",
      "```\n",
      "sh\n",
      "print(fibonacci(14))\n",
      "```\n",
      "\n",
      "This will print the 14th Fibonacci number.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING 3 CODE BLOCKS (inferred languages are [python, python, python])...\u001b[0m\n",
      "\u001b[33mcode_executor_agent_docker\u001b[0m (to code_writer_agent):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: Traceback (most recent call last):\n",
      "  File \"/workspace/tmp_code_c01864e760833511c3079490d8ca8c8b.py\", line 1, in <module>\n",
      "    sh\n",
      "NameError: name 'sh' is not defined\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mcode_writer_agent\u001b[0m (to code_executor_agent_docker):\n",
      "\n",
      "I apologize for the mistake. The code I provided earlier has a syntax error because it contains an unnecessary `sh` block at the beginning.\n",
      "\n",
      "Here's the corrected Python code to calculate the 14th Fibonacci number using recursion:\n",
      "```\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return \"Input should be positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "\n",
      "print(fibonacci(14))\n",
      "```\n",
      "Or using an iterative approach:\n",
      "```\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return \"Input should be positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "\n",
      "print(fibonacci(14))\n",
      "```\n",
      "You can copy and paste this code into your Python environment to execute it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING 2 CODE BLOCKS (inferred languages are [python, python])...\u001b[0m\n",
      "\u001b[33mcode_executor_agent_docker\u001b[0m (to code_writer_agent):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: 233\n",
      "233\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mcode_writer_agent\u001b[0m (to code_executor_agent_docker):\n",
      "\n",
      "The code I provided earlier correctly calculates the 14th Fibonacci number as 233.\n",
      "\n",
      "Here's a breakdown of how the calculation works:\n",
      "\n",
      "* The Fibonacci sequence starts with 0 and 1.\n",
      "* To calculate the next number in the sequence, you add the previous two numbers together. For example, to get the third number (2), you add the first number (0) and the second number (1).\n",
      "* This process is repeated until you reach the desired number.\n",
      "\n",
      "In this case, we are calculating the 14th Fibonacci number, which is `fibonacci(14)`.\n",
      "\n",
      "The recursive function calculates the 14th number by adding the 13th number (`fibonacci(13)`) and the 12th number (`fibonacci(12)`). This process continues until it reaches the base cases (1 or 2), at which point it returns the corresponding value.\n",
      "\n",
      "The iterative function uses a loop to calculate the Fibonacci sequence up to the 14th number. It starts with `a` as 0 and `b` as 1, then iteratively updates `a` and `b` by assigning `b` to `a` and `a + b` to `b`, respectively.\n",
      "\n",
      "Both functions correctly return the value of the 14th Fibonacci number, which is 233.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  exit\n"
     ]
    }
   ],
   "source": [
    "chat_result = code_executor_agent_using_docker.initiate_chat(\n",
    "    code_writer_agent,\n",
    "    message=\"Write Python code to calculate the 14th Fibonacci number.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "30cb43d7-c80e-4d18-a839-8fd61a39513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d7d06e9a-9fb9-4064-9bc0-7d0d000f1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35fc893-552f-45ac-969c-faadd1c9fc40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-ag",
   "language": "python",
   "name": ".venv-ag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
